----
title: "09-Combining-MIC-and-disc-diffusion-analysis"
author: "Andrew Balmer"
date: "2024-01-28"
output: html_document
---

```{r setup, include=FALSE}

# Clear the workspace
remove(list = ls())

# Load required packages
library(tidyverse)     # For data manipulation and visualization
library(smacof)        # For multidimensional scaling
library(RColorBrewer)  # For color palettes
library(calibrate)     # For calibration
library(matrixStats)   
library(ggExtra)       # For marginal histograms
library(ggdensity)     # For density distrbutions
library(foreach)
library(doParallel)

# Set the working directory
setwd("/Users/ajb306/AMR-cartography/analysis/01-Phenotype_and_map_analyses/09-12-Cross-validation-analyses/")

# Read the MIC table data
tablemic <- read.csv("/Users/ajb306/AMR-cartography-results/data/MIC_table_Spneumoniae.csv", header=TRUE, sep=",", skip = 0)

# Read in the relevant meta data
tablemic_meta <- read.csv("/Users/ajb306/AMR-cartography-results/data/meta_data_Spneumoniae.csv", header=TRUE, sep=",", skip = 0)

# Specify the full path to the data file
phen_map <- "/Users/ajb306/AMR-cartography-results/data/Spneumo_3628_PCA_start_2D_METRIC.RData"

# Load the pre-computed PCA start 2D metric data
load(phen_map)

colnames(tablemic_meta) <- c("LABID", "PT", "Penicillin_MIC", "Amoxicillin_MIC", "Meropenem_MIC", "Cefotaxime_MIC", "Ceftriaxone_MIC", "Cefuroxime_MIC")
colnames(tablemic)


```



```{r, echo=F}

set.seed(1234)
no_bootstraps <- 100

bootstrap_samples <- list()

for(i in 1:no_bootstraps) {
  bootstrap_samples[[i]] <- cbind(tablemic_meta[,1], tablemic)
  bootstrap_samples[[i]] <- bootstrap_samples[[i]] %>%
    rename(LABID = 1)
  bootstrap_samples[[i]] <- left_join(bootstrap_samples[[i]], tablemic_meta, by = "LABID")
}

disc_diffusion_samples <- list()
combinations <- list()

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

for(i in 1:no_bootstraps) {
bootstrap_samples[[i]] <- bootstrap_samples[[i]]  %>% 
  mutate(Penicillin_MIC = ifelse(Penicillin_MIC <= 0.06, "S", "R"),
         Amoxicillin_MIC = ifelse(Amoxicillin_MIC <=2, "S",ifelse(Amoxicillin_MIC==4, "I", "R")),
         Meropenem_MIC = ifelse(Meropenem_MIC <=0.25, "S",ifelse(Meropenem_MIC==0.5, "I", "R")),
         Cefotaxime_MIC = ifelse(Cefotaxime_MIC <=0.5, "S",ifelse(Cefotaxime_MIC==1, "I", "R")),
         Ceftriaxone_MIC = ifelse(Ceftriaxone_MIC <=0.5, "S",ifelse(Ceftriaxone_MIC==1, "I", "R")),
         Cefuroxime_MIC = ifelse(Cefuroxime_MIC <=0.5, "S",ifelse(Cefuroxime_MIC==1, "I", "R"))) %>%
  unite("res_comb", Penicillin_MIC:Cefuroxime_MIC, remove = FALSE) %>%
  unite("dist_comb", Penicillin:Cefuroxime, remove = FALSE) %>%
  add_count(res_comb)


disc_diffusion_samples[[i]] <- sample_n(filter(bootstrap_samples[[i]], n != 1), nrow(filter(bootstrap_samples[[i]], n != 1))*10/100)


bootstrap_samples[[i]] <- bootstrap_samples[[i]]  %>% 
  select(!n) %>%
  filter(!LABID %in% as.vector(disc_diffusion_samples[[i]]$LABID)) 

combinations[[i]] <- bootstrap_samples[[i]]  %>% 
  group_by(res_comb) %>%
  summarise(most_common_comb = Mode(dist_comb))

disc_diffusion_samples[[i]] <- left_join(disc_diffusion_samples[[i]], combinations[[i]], by = "res_comb") %>%
  select(LABID, most_common_comb) %>%
  separate(most_common_comb, c("Penicillin", "Amoxicillin", "Meropenem", "Cefotaxime", "Ceftriaxone", "Cefuroxime"), "_")

bootstrap_samples[[i]] <- bootstrap_samples[[i]] %>%
  select(LABID, Penicillin:Cefuroxime) 

bootstrap_samples[[i]] <- rbind(bootstrap_samples[[i]], disc_diffusion_samples[[i]])
bootstrap_samples[[i]] <- left_join(select(tablemic_meta, LABID), bootstrap_samples[[i]], by = "LABID") 

}





bootstrap_samples_dists <- list()

for (i in 1:no_bootstraps) {
bootstrap_samples_dists[[i]] <- dist(bootstrap_samples[[i]][, 2:7])
}


temp_weight_bootstrap_samples <- list()

for (i in 1:no_bootstraps) {
temp_weight_bootstrap_samples[[i]] <- dissWeights(bootstrap_samples_dists[[i]], type = "unif")
}

bootstrap_samples_values <- list()

for (i in 1:no_bootstraps) {
bootstrap_samples_values[[i]] <- bootstrap_samples[[i]]
}


for (i in 1:no_bootstraps) {
bootstrap_samples_values[[i]] <- bootstrap_samples_values[[i]] %>%
  filter(!LABID %in% as.vector(disc_diffusion_samples[[i]]$LABID)) 

disc_diffusion_samples[[i]][,2:7] <- NA
bootstrap_samples_values[[i]] <- rbind(bootstrap_samples_values[[i]], disc_diffusion_samples[[i]])
  
bootstrap_samples_values[[i]] <- bootstrap_samples_values[[i]] %>% pivot_longer(!LABID, names_to = "drug", values_to = "MIC_value")
}

tablemic_real_values <- cbind(tablemic_meta[,1], tablemic)

tablemic_real_values <- tablemic_real_values %>% 
  rename(LABID = 1)

tablemic_real_values <- tablemic_real_values %>% pivot_longer(!LABID, names_to = "drug", values_to = "true_value")

for (i in 1:no_bootstraps) {
bootstrap_samples_values[[i]]$LABID <- as.character(bootstrap_samples_values[[i]]$LABID)
bootstrap_samples_values[[i]] <- left_join(bootstrap_samples_values[[i]], tablemic_real_values, by = c("LABID" = "LABID", "drug" = "drug")) %>%
  mutate(dataset = i)
}

dist_pne <- dist(tablemic)





bootstrap_samples_weight_matrices <- list()
bootstrap_samples_2 <- list()



for (i in 1:no_bootstraps) {
bootstrap_samples_2[[i]] <- bootstrap_samples[[i]] %>%
  filter(!LABID %in% as.vector(disc_diffusion_samples[[i]]$LABID)) 

disc_diffusion_samples[[i]][,2:7] <- NA
bootstrap_samples_2[[i]] <- rbind(bootstrap_samples_2[[i]], disc_diffusion_samples[[i]])
bootstrap_samples_2[[i]] <- left_join(select(tablemic_meta, LABID), bootstrap_samples_2[[i]], by = "LABID") 

}


for (i in 1:no_bootstraps) {
test <- rowCounts(as.matrix(bootstrap_samples_2[[i]][,2:7]), value = NA, na.rm = FALSE)

test <- (test * -1)
test <- test + -min(test, na.rm = T) +1

bootstrap_samples_weight_matrices[[i]] <- matrix(1, nrow(tablemic),nrow(tablemic))

#dist_pne <- as.matrix(dist_pne)



for (f in 1:ncol(dist_pne)) {
bootstrap_samples_weight_matrices[[i]][,f] <- test * bootstrap_samples_weight_matrices[[i]][,f] 
}


bootstrap_samples_weight_matrices[[i]] <- t(bootstrap_samples_weight_matrices[[i]])


for (f in 1:ncol(dist_pne)) {
bootstrap_samples_weight_matrices[[i]][,f] <- test * bootstrap_samples_weight_matrices[[i]][,f] 
}

diag(bootstrap_samples_weight_matrices[[i]])=0
}



for (i in 1:no_bootstraps) {
bootstrap_samples_weight_matrices[[i]] <- bootstrap_samples_weight_matrices[[i]] * bootstrap_samples_weight_matrices[[i]]
}


# a check to make sure the weighting worked:
for (i in 1:no_bootstraps) {
temp_weight_bootstrap_samples[[i]] <- bootstrap_samples_weight_matrices[[i]] * as.matrix(temp_weight_bootstrap_samples[[i]])
}

x <- as.data.frame(as.matrix(bootstrap_samples_weight_matrices[[1]]))
y <- as.data.frame(as.matrix(temp_weight_bootstrap_samples[[1]]))
x = y

sum(is.na(temp_weight_bootstrap_samples[[1]]))
  
```


```{r, echo = F}

# Save an object to a file
#saveRDS(bootstrap_samples_weight_matrices, file = "bootstrap_samples_dists_mds_disc_mic_comb_weight_matrices.rds")
# Restore the object
bootstrap_samples_weight_matrices <- readRDS(file = "bootstrap_samples_dists_mds_disc_mic_comb_weight_matrices.rds")

# Save an object to a file
#saveRDS(bootstrap_samples, file = "bootstrap_samples_disc_mic_comb.rds")
# Restore the object
bootstrap_samples <- readRDS(file = "bootstrap_samples_disc_mic_comb.rds")

# Save an object to a file
#saveRDS(bootstrap_samples_dists, file = "bootstrap_samples_dists_disc_mic_comb.rds")
# Restore the object
bootstrap_samples_dists <- readRDS(file = "bootstrap_samples_dists_disc_mic_comb.rds")

# Save an object to a file
#saveRDS(bootstrap_samples_values, file = "bootstrap_samples_values_disc_mic_comb.rds")
# Restore the object
bootstrap_samples_values <- readRDS(file = "bootstrap_samples_values_disc_mic_comb.rds")

# Save an object to a file
#saveRDS(disc_diffusion_samples, file = "bootstrap_samples_dists_disc_diff_samples.rds")
# Restore the object
disc_diffusion_samples <- readRDS(file = "bootstrap_samples_dists_disc_diff_samples.rds")

```



### ==== Background

Measuring resistance phenotypes using MIC dilution series can be challenging to analyse. One issues in analysis of AMR surveillance data is that isolates within a collection may have been phenotyped using different susceptibility testing methods. This is common where data has been pooled from different experiments or surveillance projects. In other cases, an alternative testing method may have been used as part of a pilot experiment or data collected by collaborators without training in a particular method. Unfortunately this is an issue for analysis as the two methods typically cannot be analysed using the same tools.  In all of these cases separate analyses need to be conducted on the isolates with MIC values and then the isolates with cut-offs.

One benefit of the cartography framework is it should theoretically be able to incorporate multiple assays in the same analysis. This is because it is able to combine a mixture of metric and non-metric information simultaneously. For example,  the MIC assay provides a mixture of metric and non-metric information and the disc diffusion data provides non-metric information, simply providing a cutoff Sensitive, Intermediate or Resistant value. By weighting the non-metric information less strongly when generating the maps, MDS should be able too position these isolates based on the information available, despite the imprecision of disc diffusion data. 

One important limitation is that it is only  possible to combine the data in cases there the two assays are calibrated in such a way as to be able to place them on the same scale. For example, if a Sensitive breakpoint value provided by the disc diffusion data would need to equal e.g. <2ug/ml on the MIC assay, an intermediate value equals 4ug/ml and a resistant value equals >8ug/ml, and so on. If such a calibrated scale is not available it would be much more difficult to position the isolates relative to each other. Usually it is case that this calibration is available.


## Aims and objectives 
In this document, I have used a range of tools to test whether MDS is able to combine MIC and artificially generated disc diffusion values. I used several methods to test the accuracy of the predictions. To do this I artifically cut-off MIC values for a subset of isolates across all drugs. For example, if an isolates value for 16ug/ml for Penicillin, and the Resistant cut-off threshold for this drug is >8ug/ml. Then that isolates value would be changed to >8ug/ml. I did this for all 6 MIC values for 10% of the isolates in the dataset. I generated 100 datasets with cut-off values for 10% of the isolates. 

I then tested the ability of the MDS methods to work with this data. Firstly, I tried making maps with combined cut-off and MIC data and comparing them to the original maps made with the observed MIC values. I did this using Procrustes analysis to rotate and dilate the the two maps into the same positions. I then compared the two maps using the correlation of values on the two maps. Secondly, I measured the euclidean distance between the true value on the map and its position with when using the cut-off values. I compared these distances for the two dimensional maps, but also completed a cross-validation analysis, comparing error for maps made in other dimensions. Thirdly I then also generated calibrated biplot axes of the maps made with cut-off values. This allowed me to calculate the MIC values predicted by the map/biplot axes and calculate their difference from the true value. 

I also calculated the levels of stress for the cut-off-value maps, as well as stress-per-point for the isolates with and without cut-off values. 

As the following analysis is quite computationally intensive for such a large dataset, for now, I have only ran the analysis on 1 of these 100 samples to make it tractable to run on my laptop. However, I plan to run the analysis using the Hamilton server for the full 100 maps. I will also complete the same analysis for the S. suis beta-lactam map. 


### Generating distance matrices with missing values and weighting points
Firstly, as mentioned above dataset, 100 datasets were created, each with 10% of the isolates taken and all of their 6 MIC values converted to cut-off breakpoints. The MDS algorithm needs an initial position to place the isolates. They therefore need to be included in the pairwise distance matrix.

To generate a starting position, I calculated the most common MIC values for a given combination of sensitive/resistant cut-offs. For example each isolate has a combination of cut-off values for the 6 drugs, e.g.:

S_S_R_S_R_S (S=sensitive, R=resistant)

As this is based on their MIC values (e.g. R = >8ug/ml), this means it is possible calculate the cut-off combination for isolates which did have MIC values measured. For each combination of cut-offs, I calculated the most common MIC values for the six drugs:

S_S_R_S_R_S = 1ug/ml__2ug/ml__8ug/ml__1ug/ml__8ug/ml__1ug/ml

For the isolates with only cut-off data, I imputed these MIC values as their starting coordinates for the isolates without MIC data, as they were the most common among isolates with the same cut-off combination. For each sample dataset (10% of isolates with cut-off data), I calculated the most common-cut-off combinations based only on the remaining 90% of isolates. 

A pairwise distance matrix for each dataset was then generated. This is useful as it provided the MDS algorithm initial information on where to place the isolate, the iterative steps can then be used to improve the predictioon based on the position of the rest of the isolates.

Isolates with cut-off values only were also given less weight in generating the map. This was done to prevent these isolates strongly affecting the position of other isolates which had more information on where to position them. To do this, a weight matrix was constructed for each of the 100 samples based on how may MIC values were missing for each isolate. To generate this weight matrix, the pairwise distance between each pair of isolates was weighted by multiplying the number of MIC values present for that pair of isolates, then squaring the result

e.g. isolate 1 has 0 MIC values (+1), isolate 2 has 6(+1), so the weight for that isolate would be 7. The +1 was added to each number of MIC values as the weighting cannot operate on points with 0 weight. These values were then squared, to make 49. The absolute values of the weight matrix is less important than the differences between them. Finding the precise weighting structure with the least prediction error is a process of trial and error, but this structure seems to work well as an initial estimate (see below). The MDS algorithm was then used to generate a map for each the sample dataset, using the metric, PCoA start method.


```{r, echo = FALSE}

bootstrap_samples_dists_mds <- list()

# ==== DEFINE MDS WRAPPER FUNCTION (now includes LABID tracking) ====
run_mds <- function(dist_matrix, weight_matrix, ids, ndim = 2) {
  temp_MDS <- mds(
    delta     = dist_matrix,
    ndim      = ndim,
    type      = "ratio",
    weightmat = weight_matrix,
    init      = "torgerson",
    modulus   = 1,
    itmax     = 1000,
    eps       = 1e-06
  )
  return(list(
    conf   = temp_MDS$conf,
    stress = temp_MDS$stress,
    spp    = temp_MDS$spp,
    LABID  = ids
  ))
}

# ==== PARALLEL BATCHED EXECUTION OF MDS ====

# Set number of bootstraps, batch size, and cores
no_bootstraps <- 100
batch_size <- 10        # Run 5 at a time
num_cores <- 2          # Use 2 cores to stay within RAM limits

# Register parallel backend
library(doParallel)
registerDoParallel(cores = num_cores)

# Create list to store file paths for each batch
all_batches_paths <- list()

# Loop through bootstrap samples in batches
for (start in seq(1, no_bootstraps, by = batch_size)) {
  
  end <- min(start + batch_size - 1, no_bootstraps)
  cat("Processing batch", start, "to", end, "...\n")
  
  # Run MDS in parallel across current batch
  mds_results <- foreach(i = start:end, .packages = c("smacof")) %dopar% {
    run_mds(
      dist_matrix   = bootstrap_samples_dists[[i]],
      weight_matrix = bootstrap_samples_weight_matrices[[i]],
      ids           = bootstrap_samples[[i]]$LABID
    )
  }
  
  # Save this batch to file
  batch_file <- paste0("bootstrap_mds_batch_", start, "_to_", end, ".rds")
  saveRDS(mds_results, file = batch_file)
  all_batches_paths[[length(all_batches_paths) + 1]] <- batch_file
  
  # Free memory
  rm(mds_results)
  gc()
}

# Stop parallel backend
registerDoSEQ()

# ==== OPTIONAL: Load all batches later into one object ====

# Reconstruct full list of results (if needed)
batch_files <- list.files(pattern = "bootstrap_mds_batch_.*\\.rds")
bootstrap_samples_dists_mds <- lapply(batch_files, readRDS) %>% unlist(recursive = FALSE)





```




```{r, echo =F}
# Set the rotation angle in radians
theta <- 326 * pi / 180

# Create a rotation matrix
rot <- matrix(c(cos(theta), sin(theta), -sin(theta), cos(theta)), ncol = 2)

# Apply rotation to the configuration data
torg_met$conf <- torg_met$conf %*% rot

bootstrap_samples_dists_confs <- list()

for (i in 1:100) {
bootstrap_samples_dists_confs[[i]] <- as_tibble(bootstrap_samples_dists_mds[[i]]$conf)
}

bootstrap_samples_stress <- vector()

for (i in 1:100) {
bootstrap_samples_stress[i] <- bootstrap_samples_dists_mds[[i]]$stress
}

bootstrap_samples_stress <- as_tibble(bootstrap_samples_stress)

torg_met_conf <- as.data.frame(torg_met$conf)

```


### Congruence coefficient.

To more quantitatively compare the maps, I used procrustes to rotate and dilate the maps into the same rotation. I first calculated the congruence coefficient between the sets of maps which can be used too compare the similarity of two solutions (https://en.wikipedia.org/wiki/Congruence_coefficient#:~:text=In%20multivariate%20statistics%2C%20the%20congruence,derived%20in%20a%20factor%20analysis.&text=It%20can%20be%20used%20to,have%20taken%20the%20same%20test.)

Below, the plot shows that the maps with 10% cut-off values are essentially the same as the one made all MIC values these isolates. This suggests the cut-off values are not having a strong effect on how the maps are positioning the isolates with actual values. Generally, a congruence coefficient aboove 0.95 is considered very similar, and above .99 is near identical For each transformation here, the estimate is >0.998, suggesting the solutions are essentially the same. While there are more fine-grain measures to measure error for the isolates with cut-off values (see below), this parameter provides a good estimate of the overall similarity of the maps.

```{r, echo = F}

table_distances <- as_tibble(as.matrix(torg_met[[1]]))
map_distances <- as_tibble(as.matrix(torg_met[[3]]))

colnames(map_distances) <- colnames(table_distances)
table_distances <- gather(table_distances,"antibiotic","table_distance", 1:nrow(tablemic)) 

map_distances <- gather(map_distances,"antibiotic","map_distance", 1:nrow(tablemic))

distances <- bind_cols(table_distances, map_distances)

distances$table_distance <- as.numeric(distances$table_distance)
distances$map_distance <- as.numeric(distances$map_distance)
mapvtable <- lm(map_distance ~ table_distance, data = distances)
#summary(mapvtable)
#mapvtable
#coef(mapvtable)
# transformation - 0.178413576


slope <- as.numeric(coef(mapvtable)[2])
#slope <- 0.1843009
dilation <- 1/slope
colnames(torg_met_conf) <- c("D1","D2")



for (i in 1:ncol(torg_met_conf)) {
  torg_met_conf[,i] <- torg_met_conf[,i] *dilation
  
}
#torg_met_conf$D1 <- torg_met_conf$D1 * dilation
#torg_met_conf$D2 <- torg_met_conf$D2 * dilation



met_ord_comparison <- list()
met_ord_comparison_congcoef <- vector()
met_ord_comparison_aliencoef <- vector()
#bootstrap_samples_dists_confs[[1]] <- torg_met_conf
for (i in 1:100) {
met_ord_comparison[[i]] <- Procrustes(as.matrix(torg_met_conf), as.matrix(bootstrap_samples_dists_confs[[i]]))
met_ord_comparison_congcoef[i] <- met_ord_comparison[[i]]$congcoef
met_ord_comparison_aliencoef[i] <- met_ord_comparison[[i]]$aliencoef
}


met_ord_comparison_congcoef <- as_tibble(met_ord_comparison_congcoef)

round(mean(met_ord_comparison_congcoef$value),3)

B <- ggplot(met_ord_comparison_congcoef, aes(x=value)) + 
  geom_histogram(position="identity", alpha = 0.5, color = "black", fill = "#E41A1C", bins = 30) + 
  geom_vline(aes(xintercept=mean(value)),
            color="#E41A1C", linetype="dashed", size=1) + 
  geom_vline(aes(xintercept=0.99),
            color="black", linetype="solid", size=1) +
  theme_bw() +
  labs(x = "Congruence Coefficient", y = "Count") 
#+
#  coord_fixed(ratio = .025) 
B
ggsave("S_pneumo_comb_cong_conf.jpg")


#met_ord_comparison_aliencoef <- as_tibble(met_ord_comparison_aliencoef)

#ggplot(met_ord_comparison_aliencoef, aes(x=value)) + 
#  geom_histogram(position="identity", alpha = 0.5, color = "black", bins = 30) + 
#  geom_vline(aes(xintercept=mean(value)),
#            color="grey", linetype="dashed", size=.5) + 
  #geom_vline(aes(xintercept=0.95),
  #          color="black", linetype="solid", size=1) +
#  theme_bw()   

#met_ord_comparison[[1]]$Y <- met_ord_comparison[[1]]$X

#plot(met_ord_comparison[[1]], plot.type = "transplot", arrows = T, length = 0.05, ylim = c(-1,1), 
#     legend = list(pos = "bottomright", 
#     labels = c("Real map", "comb added map")))

#met_ord_comparison[[2]]$Y <- met_ord_comparison[[2]]$X

#plot(met_ord_comparison[[2]], plot.type = "transplot", arrows = T, length = 0.05, ylim = c(-1,1), 
#     legend = list(pos = "bottomright", 
#                   labels = c("Real map", "comb added map")))
#head(bootstrap_samples_dists_confs[[1]])
#head(torg_met_conf)

#plot(met_ord_comparison[[1]]$X, met_ord_comparison[[1]]$Yhat)

```


### Testing whether datasets with additional error have higher stress

In MDS, stress is the sum of the squared distances between the points on the plot and their distances in the original data table. This is the parameter MDS tries to minimise when making the map. Theoretically, given there strong correlations between MICs to the different drugs, adding cut-off values might effect their stress values  on the map. This is because the cut-off values may have the effect of altering those correlations, and meaning the distances can not be as well represented in 2 dimensions. 

I estimated stress for each of the maps with cut-off values (histogram) and compared them to the stress for the original map (black line). Notably, the cut-off value map had slightly higher stress than the original map. However, the isolates with cut-off values did not tend to have an obviously higher level of stress-per-point (as a % of total stress). Below is the histogram of stress per point for the cut-off values(red) compared to the other isolates on the map (grey). The stress for the points with cut-off values is slightly larger than those without.



```{r, echo = F}

for (i in 1:100) {
met_ord_comparison[[i]]$pairwise_dist <- cbind(met_ord_comparison[[i]]$X, met_ord_comparison[[i]]$Yhat)

colnames(met_ord_comparison[[i]]$pairwise_dist) <- c("D1_X", "D2_X","D1_Y","D2_Y")

met_ord_comparison[[i]]$pairwise_dist <- as_tibble(met_ord_comparison[[i]]$pairwise_dist) %>% 
     mutate(dist_phen = sqrt((D1_X-D1_Y)^2 + (D2_X-D2_Y)^2),
            LABID = tablemic_meta[,1]) 


bootstrap_samples_dists_mds[[i]]$spp <- cbind(tablemic_meta$LABID, bootstrap_samples_dists_mds[[i]]$spp)
colnames(bootstrap_samples_dists_mds[[i]]$spp) <- c("LABID", "spp")
#colnames(as_tibble(bootstrap_samples_dists_mds[[i]]$spp))
#colnames(as_tibble(met_ord_comparison[[i]]$pairwise_dist))

met_ord_comparison[[i]]$pairwise_dist <- left_join(met_ord_comparison[[i]]$pairwise_dist, as_tibble(bootstrap_samples_dists_mds[[i]]$spp), by = "LABID")

}

#median(met_ord_comparison[[1]]$pairwise_dist$dist_phen)

torg_met_conf <- cbind(torg_met_conf, tablemic_meta$LABID, torg_met$spp)
colnames(torg_met_conf) <- c("D1","D2","LABID", "stress_per_point_real")

stress_per_point_comp <- list()
#head(met_ord_comparison[[1]]$pairwise_dist)

for (i in 1:100) {
stress_per_point_comp[[i]] <- left_join(met_ord_comparison[[i]]$pairwise_dist, bootstrap_samples_values[[i]], by = "LABID")

stress_per_point_comp[[i]]$spp <- as.numeric(stress_per_point_comp[[i]]$spp)

stress_per_point_comp_2 <- left_join(stress_per_point_comp[[i]], torg_met_conf, by = "LABID") %>%
 group_by(LABID) %>%
 summarize(count_na = sum(is.na(MIC_value)))

stress_per_point_comp[[i]] <- left_join(stress_per_point_comp[[i]], stress_per_point_comp_2, by = c("LABID" = "LABID")) #%>%
# distinct(LABID, dataset, .keep_all = T) 

#stress_per_point_comp[[i]]$n[is.na( stress_per_point_comp[[i]]$n)] <- 0
stress_per_point_comp[[i]]$spp <- as.numeric(stress_per_point_comp[[i]]$spp)

stress_per_point_comp[[i]]<- stress_per_point_comp[[i]] %>%
  mutate(dataset = i)
}

test <- bind_rows(stress_per_point_comp) %>%
  distinct(LABID, dataset, .keep_all = TRUE)


test_2 <- test %>% mutate(missing_values = ifelse(count_na == "0", "No missing values","Missing values")) 

mu <- test_2 %>%
group_by(missing_values) %>%
    summarize(Mean = mean(spp, na.rm=TRUE),
              Median = median(spp, na.rm=TRUE))

round(mu$Mean[1] - mu$Mean[2],3)
#mu[,2:3] <- round(mu[,2:3], 3)

ggplot(as_tibble(bootstrap_samples_stress), aes(x=value)) + 
  geom_histogram(color="black", alpha = 0.5, fill="#E41A1C", bins =20) +
  theme_bw() +
  geom_vline(xintercept = torg_met$stress) +
    labs(x = "Overall map stress", y = "Count") 


E <- ggplot(test_2, aes(spp, y = stat(density), colour = missing_values, fill = missing_values)) + 
  geom_histogram(position="identity", alpha = 0.45, color = "black") + 
  geom_freqpoly(bins = 30 , stat = "bin") + 
  theme_bw() + 
  geom_vline(data=mu, aes(xintercept=Mean, color=missing_values),
             linetype="dashed", size = .75) +
   #scale_x_continuous(breaks=seq(0, max(abs(test_2$spp), na.rm = T) + .2, .2)) +
   scale_y_continuous(breaks=seq(0, 60, 10))   +
  labs(x = "Stress per point (%)", y = "Density") +
  #theme(legend.justification=c(.95,.725), legend.position=c(.95,.8)) + 
  theme(legend.position = "none") + 
  guides(colour = "none")  +
  guides(fill=guide_legend(title="Error added")) +
  scale_colour_manual(values=c(  "#E41A1C","darkgrey")) +
  scale_fill_manual(values=c(   "#E41A1C","darkgrey"))

E
ggsave("S_pneumo_comb_spp.jpg")


```


### Euclidean distance between true values and predicted values

After reorientation of the cut-off value maps to compare to the real map, I then estimated the euclidean distance between each isolates true value on the map made with the MIC values and their position no the map made with the cut-off values. Below is a histogram of those values for the isolates with cut-off MICs (Red) and the distances for those when MIC values were used (grey). Typically the values were less than 1 MIC unit away from their true values. However, some points were slightly further away from their true values. 


```{r, echo = F}
mu <- test_2 %>%
  group_by(missing_values) %>%
  summarize(
    Mean = round(mean(dist_phen, na.rm = TRUE), 3),
    SD = round(sd(dist_phen, na.rm = TRUE), 3)
  )

round(mu$Mean[1], 3)

C <- ggplot(filter(test_2, true_value != 1), aes(dist_phen, y = stat(density), colour = missing_values, fill = missing_values)) + 
  geom_histogram(position = "identity", alpha = 0.45, color = "black") + 
  geom_freqpoly(bins = 40, stat = "bin") + 
  theme_bw() + 
  geom_vline(data = mu, aes(xintercept = Mean, color = missing_values),
             linetype = "dashed", size = 0.75) +
  geom_vline(aes(xintercept = 1), color = "black",
             linetype = "solid", size = 0.5) +
  labs(x = "Distance from true value (MIC units)", y = "Density") +
  theme(legend.justification = c(0.95, 0.725), legend.position = c(0.95, 0.8)) + 
  guides(colour = "none") +
  guides(fill = guide_legend(title = "Error added")) +
  scale_colour_manual(values = c("#E41A1C", "darkgrey")) +
  scale_fill_manual(values = c("#E41A1C", "darkgrey")) +
  theme(legend.position = "none")

C

ggsave("S_pneumo_comb_euc_phen_dist.jpg")

# Estimate proportion of distances < 1 MIC unit
count_less_than_1 <- test_2 %>%
  group_by(missing_values) %>%
  summarise(
    count_total = n(),
    count_less_than_one = sum(dist_phen < 1, na.rm = TRUE),
    prop_less_than_one = round(count_less_than_one / count_total * 100, 3)
  )

print(count_less_than_1)

# Also calculate >1 MIC unit error
count_greater_than_1 <- test_2 %>%
  group_by(missing_values) %>%
  summarise(
    count_total = n(),
    count_greater_than_one = sum(dist_phen > 1, na.rm = TRUE),
    prop_greater_than_one = round(count_greater_than_one / count_total * 100, 3)
  )

print(count_greater_than_1)

# Calculate exact percentages (optional)
100 - count_less_than_1$prop_less_than_one

count_dist_bins <- test_2 %>%
  group_by(missing_values) %>%
  summarise(
    count_total = n(),
    count_lt_1 = sum(dist_phen < 1, na.rm = TRUE),
    count_1_to_2 = sum(dist_phen >= 1 & dist_phen < 2, na.rm = TRUE),
    count_ge_2 = sum(dist_phen >= 2, na.rm = TRUE),
    prop_lt_1 = round(count_lt_1 / count_total * 100, 3),
    prop_1_to_2 = round(count_1_to_2 / count_total * 100, 3),
    prop_ge_2 = round(count_ge_2 / count_total * 100, 3)
  )

print(count_dist_bins)

```



## Comparing the number of missing values with prediction error

```{r,echo = f}
library(dplyr)
library(ggplot2)

mapvtable <- NULL
bootstrap_samples_weight_matrices <- NULL
bootstrap_samples_dists <- NULL

# Deduplicate: one row per LABID-dataset pair, keeping count_na and missing_values
dedup_data <- test_2 %>%
  group_by(LABID, dataset) %>%
  summarise(
    dist_phen = mean(dist_phen, na.rm = TRUE),
    count_na = mean(count_na, na.rm = TRUE),
    D1_X = mean(D1_X, na.rm = TRUE),
    D2_X = mean(D2_X, na.rm = TRUE),
    missing_values = first(missing_values),
    .groups = "drop"
  )


# Add radial distance from MDS center
dedup_data <- dedup_data %>%
  mutate(dist_from_center = sqrt((D1_X - mean(D1_X, na.rm = TRUE))^2 + 
                                 (D2_X - mean(D2_X, na.rm = TRUE))^2),
         count_na = as.factor(count_na))  # convert to factor for grouping & plotting

# Bin distance and summarise error by bin and count_na
summary_by_bin <- dedup_data %>%
  mutate(dist_bin = cut(dist_from_center, breaks = 10)) %>%
  group_by(dist_bin) %>%
  summarise(
    center = mean(dist_from_center, na.rm = TRUE),
    mean_dist_phen = mean(dist_phen, na.rm = TRUE),
    sd_dist_phen = sd(dist_phen, na.rm = TRUE),
    n = n(),
    se = sd_dist_phen / sqrt(n),
    .groups = "drop"
  )

# Plot mean error by distance and count_na
ggplot(summary_by_bin, aes(x = center, y = mean_dist_phen)) +
  geom_point(size = 3) +
  geom_line(aes()) +
  geom_errorbar(aes(ymin = mean_dist_phen - se, ymax = mean_dist_phen + se), width = 0.1) +
  theme_bw() +
  labs(x = "Distance from mean centroid map position (MIC units)",
       y = "Mean Prediction Error (dist_phen)",
       colour = "Missing Values") +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(size = 15, face = "bold")
  )

# Tabulate prediction error summaries by distance and count_na
summary_dist_center <- dedup_data %>%
  mutate(dist_bin = cut(dist_from_center, breaks = 10)) %>%
  group_by(dist_bin) %>%
  summarise(
    mean_error = round(mean(dist_phen, na.rm = TRUE), 3),
    median_error = round(median(dist_phen, na.rm = TRUE), 3),
    max_error = round(max(dist_phen, na.rm = TRUE), 3),
    prop_below_1 = round(mean(dist_phen <= 1, na.rm = TRUE), 3),
    .groups = "drop"
  )
print(summary_dist_center)


```


### Visually comparing a comb-added map to true values

I then plotted a map made with cut-off values and the original map on the same plot after reorienting them to the same scale/rotation. Here, the black points are the true values, while the red points are the cut-off added values. The black crosses indicate points which did not have cut-off added. Although it is a little difficult to see because of the number of points, most values are within 1log fold of their true value (see above).


```{r, echo = F}


test <- test %>% mutate(missing_values = ifelse(count_na == "0", "No missing values","Missing values")) 

#range(test$D1_X, test_2$D1_X)
#test_2 
A <- ggplot(filter(test_2, missing_values != "No missing values" & dataset == 1 ), aes(x=D1_X, y=D2_X)) + 
  geom_point(data = filter(test, missing_values == "No missing values" & dataset == 1), aes(x=D1_X, y=D2_X), shape = 4, fill = "grey", size = 1.5, alpha = 0.6)+
    geom_segment(data = filter(test_2, missing_values != "No missing values" & dataset == 1), aes(x = D1_X, y = D2_X, xend = D1_Y, yend = D2_Y), size = .5, colour = "grey") + 
  geom_point(data = filter(test_2, missing_values != "No missing values" & dataset == 1), shape = 21, fill = "black", size = 2, colour = "white") + 
  geom_point(data = filter(test_2, missing_values != "No missing values" & dataset == 1), aes(x=D1_Y, y=D2_Y), shape = 21, fill = "#E41A1C", size = 2, colour = "white") +
  theme_bw() +   
  #facet_wrap(~ dataset)+
 scale_x_continuous(limits = c(min(test_2$D1_X, na.rm = T), max(test_2$D1_X, na.rm = T)+ .5), breaks=seq(min(test_2$D1_X, na.rm = T), max(test_2$D1_X, na.rm = T) + 1,  1))   +
  scale_y_continuous(limits = c(min(test_2$D2_X, na.rm = T), max(test_2$D2_X, na.rm = T)+ .5), breaks=seq(min(test_2$D2_X, na.rm = T), max(test_2$D2_X, na.rm = T) + 1,  1)) +
  labs(title ="") +
  labs( x = "MDR distance", y = "MDR distance") + 	
  theme(axis.text=element_text(size=16), 
        axis.title=element_text(size=16), 
        panel.grid.major = element_line(colour="grey", size = (0.3)),
        panel.grid.minor = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y = element_blank(),
        strip.text.x = element_text(size = 14)) +
  coord_fixed() 
A
ggsave("S_pneumo_comb_pred_error_map.jpg")

```





```{r, echo = FALSE}

# --- Set parameters ---
no_bootstraps <- 25
num_cores <- 2

# --- Register parallel backend ---
library(doParallel)
registerDoParallel(cores = num_cores)

# --- Initialize outer list (1 per dimension) ---
bootstrap_samples_dists_dimensions <- vector("list", 4)

# --- Run MDS for each dimension in parallel ---
for (dim in 1:4) {
  cat("Running MDS for dimension:", dim, "\n")
  
  bootstrap_samples_dists_dimensions[[dim]] <- foreach(i = 1:no_bootstraps, .packages = c("smacof")) %dopar% {
    
    temp_MDS <- mds(
      delta     = bootstrap_samples_dists[[i]],
      ndim      = dim,
      type      = "ratio",
      init      = "torgerson",
      weightmat = bootstrap_samples_weight_matrices[[i]],
      modulus   = 1,
      itmax     = 1000,
      eps       = 1e-06
    )
    
    list(
      conf   = temp_MDS$conf,
      stress = temp_MDS$stress,
      spp    = temp_MDS$spp
    )
  }
}

# --- Stop parallel backend ---
registerDoSEQ()

# --- Save results ---
#saveRDS(bootstrap_samples_dists_dimensions, file = "bootstrap_samples_dists_dimensions_disc_mic_comb.rds")

# --- Restore if needed later ---
 bootstrap_samples_dists_dimensions <- readRDS("bootstrap_samples_dists_dimensions_disc_mic_comb.rds")

# --- Load torg_met dimensions from existing results ---
torg_met_dimensions <- readRDS(file = "torg_met_dimensions_missing_values.rds")

# --- Prepare output lists for stress and coordinates ---
bootstrap_samples_dists_confs_dim <- vector("list", 4)
bootstrap_samples_stress_dim <- vector("list", 4)

for (f in 1:4) {
  bootstrap_samples_dists_confs_dim[[f]] <- list()
  bootstrap_samples_stress_dim[[f]] <- vector()
  
  for (i in 1:no_bootstraps) {
    bootstrap_samples_dists_confs_dim[[f]][[i]] <- as_tibble(bootstrap_samples_dists_dimensions[[f]][[i]]$conf)
    bootstrap_samples_stress_dim[[f]][i] <- bootstrap_samples_dists_dimensions[[f]][[i]]$stress
  }
  
  bootstrap_samples_stress_dim[[f]] <- as_tibble(bootstrap_samples_stress_dim[[f]])
}

for (f in 1:4){
bootstrap_samples_dists_confs_dim[[f]] <- list()
bootstrap_samples_stress_dim[[f]] <- vector()
}

for (f in 1:4) {
  for (i in 1:no_bootstraps) {
bootstrap_samples_dists_confs_dim[[f]][[i]] <- as_tibble(bootstrap_samples_dists_dimensions[[f]][[i]]$conf)
bootstrap_samples_stress_dim[[f]][i] <- bootstrap_samples_dists_dimensions[[f]][[i]]$stress
  }
}

#head(bootstrap_samples_dists_dimensions[[2]][[1]]$conf)


for (f in 1:4) {
bootstrap_samples_stress_dim[[f]] <- as_tibble(bootstrap_samples_stress_dim[[f]])
}


torg_met_dimensions_conf <- list()
torg_met_dimensions_stress <- vector()
#head(torg_met_dimensions[[2]]$conf)

for (f in 1:4) {
torg_met_dimensions_conf[[f]] <- as_tibble(torg_met_dimensions[[f]]$conf)
torg_met_dimensions_stress[f] <- torg_met_dimensions[[f]]$stress
}

torg_met_dimensions_stress <- as_tibble(torg_met_dimensions_stress)

slope_dim <- vector()
dilation_dim <- vector()

for (f in 1:4) {
table_distances <- as_tibble(as.matrix(torg_met_dimensions[[f]][[1]]))
map_distances <- as_tibble(as.matrix(torg_met_dimensions[[f]][[3]]))

colnames(map_distances) <- colnames(table_distances)
table_distances <- gather(table_distances,"antibiotic","table_distance", 1:nrow(tablemic)) 
map_distances <- gather(map_distances,"antibiotic","map_distance", 1:nrow(tablemic))

distances <- bind_cols(table_distances, map_distances)

distances$table_distance <- as.numeric(distances$table_distance)
distances$map_distance <- as.numeric(distances$map_distance)
mapvtable <- lm(map_distance ~ table_distance, data = distances)
#summary(mapvtable)
#mapvtable
#coef(mapvtable)
# transformation - 0.178413576

slope_dim[f] <- as.numeric(coef(mapvtable)[2])
#slope <- 0.1843009
dilation_dim[f] <- 1/slope_dim[f]
}


for (i in 1:ncol(torg_met_dimensions_conf[[1]])){
torg_met_dimensions_conf[[1]][,i] <- torg_met_dimensions_conf[[1]][,i] * dilation_dim[1]
}

for (i in 1:ncol(torg_met_dimensions_conf[[2]])){
torg_met_dimensions_conf[[2]][,i] <- torg_met_dimensions_conf[[2]][,i] * dilation_dim[2]
}

for (i in 1:ncol(torg_met_dimensions_conf[[3]])){
torg_met_dimensions_conf[[3]][,i] <- torg_met_dimensions_conf[[3]][,i] * dilation_dim[3]
}

for (i in 1:ncol(torg_met_dimensions_conf[[4]])){
torg_met_dimensions_conf[[4]][,i] <- torg_met_dimensions_conf[[4]][,i] * dilation_dim[4]
}


met_ord_comparison_dim <- list()
met_ord_comparison_congcoef_dim <- list()

for (f in 1:4){
met_ord_comparison_dim[[f]] <- list()
}


for (f in 1:4) {
  for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[f]][[i]] <- Procrustes(as.matrix(torg_met_dimensions_conf[[f]]),  as.matrix(bootstrap_samples_dists_confs_dim[[f]][[i]]))
  }
}


for (f in 1:4) {
for (i in 1:no_bootstraps) { 
colnames(met_ord_comparison_dim[[f]][[i]]$X)<-paste(colnames(met_ord_comparison_dim[[f]][[i]]$X),"X",sep="_")
colnames(met_ord_comparison_dim[[f]][[i]]$Yhat)<-paste(colnames(met_ord_comparison_dim[[f]][[i]]$Yhat),"Y",sep="_")
}}

for (f in 1:4) {
for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[f]][[i]]$pairwise_dist <- cbind(met_ord_comparison_dim[[f]][[i]]$X, met_ord_comparison_dim[[f]][[i]]$Yhat)
}}

for (f in 1:4) {
  for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[f]][[i]]$pairwise_dist <- as_tibble(met_ord_comparison_dim[[f]][[i]]$pairwise_dist)
  }}


for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[1]][[i]]$pairwise_dist <- as_tibble(met_ord_comparison_dim[[1]][[i]]$pairwise_dist) %>%
     mutate(dist_phen = sqrt((D1_X-D1_Y)^2),
            LABID = tablemic_meta[,1])
}

for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[2]][[i]]$pairwise_dist <- as_tibble(met_ord_comparison_dim[[2]][[i]]$pairwise_dist) %>%
     mutate(dist_phen = sqrt((D1_X-D1_Y)^2 + (D2_X-D2_Y)^2),
            LABID = tablemic_meta[,1])
}


for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[3]][[i]]$pairwise_dist <- as_tibble(met_ord_comparison_dim[[3]][[i]]$pairwise_dist) %>%
     mutate(dist_phen = sqrt((D1_X-D1_Y)^2 + (D2_X-D2_Y)^2 + (D3_X-D3_Y)^2),
            LABID = tablemic_meta[,1])
}


for (i in 1:no_bootstraps) {
met_ord_comparison_dim[[4]][[i]]$pairwise_dist <- as_tibble(met_ord_comparison_dim[[4]][[i]]$pairwise_dist) %>%
     mutate(dist_phen = sqrt((D1_X-D1_Y)^2 + (D2_X-D2_Y)^2 + (D3_X-D3_Y)^2 + (D4_X-D4_Y)^2),
            LABID = tablemic_meta[,1])
}




for (f in 1:4) {
for (i in 1:no_bootstraps) {
bootstrap_samples_dists_dimensions[[f]][[i]]$spp <- cbind(tablemic_meta$LABID, bootstrap_samples_dists_dimensions[[f]][[i]]$spp)
colnames(bootstrap_samples_dists_dimensions[[f]][[i]]$spp) <- c("LABID", "spp")
#colnames(as_tibble(bootstrap_samples_dists_dimensions[[f]][[i]]$spp))
#colnames(as_tibble(met_ord_comparison_dim[[f]][[i]]$pairwise_dist))

met_ord_comparison_dim[[f]][[i]]$pairwise_dist <- left_join(met_ord_comparison_dim[[f]][[i]]$pairwise_dist, as_tibble(bootstrap_samples_dists_dimensions[[f]][[i]]$spp), by = "LABID")
}
}




stress_per_point_comp <- list()
for (f in 1:4){
stress_per_point_comp[[f]] <- list()
}


for (f in 1:4) {
for (i in 1:no_bootstraps) {
stress_per_point_comp[[f]][[i]] <- left_join(as_tibble(met_ord_comparison_dim[[f]][[i]]$pairwise_dist), as_tibble(bootstrap_samples_values[[i]]), by = "LABID")
}}


stress_per_point_comp_2 <- list()
for (f in 1:4){
stress_per_point_comp_2[[f]] <- list()
}

###############
for (f in 1:4) {
for (i in 1:no_bootstraps) {
stress_per_point_comp_2[[f]][[i]] <- stress_per_point_comp[[f]][[i]] %>%
  group_by(LABID) %>%
 summarize(count_na = sum(is.na(MIC_value)))
}}

for (f in 1:4) {
for (i in 1:no_bootstraps) {
stress_per_point_comp[[f]][[i]] <- left_join(stress_per_point_comp[[f]][[i]], stress_per_point_comp_2[[f]][[i]], by = c("LABID" = "LABID")) #%>%
# distinct(LABID, dataset, .keep_all = T) 
##################


stress_per_point_comp[[f]][[i]]<- stress_per_point_comp[[f]][[i]] %>%
  mutate(dimension = f, 
         dataset = i)
}
}


test <- bind_rows(stress_per_point_comp)
test <- test %>% mutate(missing_values = ifelse(count_na == "0", "No missing values","Missing values")) 
test$dist_phen <- as.numeric(test$dist_phen)
test$dimension <-  as.factor(test$dimension)


mu <- test %>%
  filter(missing_values == "Missing values") %>%
  distinct(LABID, dimension, dataset, .keep_all = T) %>%
  ungroup() %>%
    group_by(dimension, dataset) %>%
    summarize(Mean = mean(dist_phen),
              Median = median(dist_phen))


#ggplot(mu, aes(x=dimension, y=Mean)) + 
# geom_point(color="#E41A1C")+
#  geom_line(color="#E41A1C") +
  #geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2,
   #              position=position_dodge(0.05), color="#E41A1C") +
#  theme_bw() +
#  labs(x = "Dimension", y = "Mean Prediction Error (MIC units)") 


mu <- mu %>%
    group_by(dimension) %>%
     summarize(sd = round(sd(Mean),3),
               Mean = round(mean(Mean),3),
               Median = round(median(Median),3))

t(mu)

D <- ggplot(mu, aes(x=dimension, y=Mean)) + 
  geom_point(color="#E41A1C")+
  geom_line(color="#E41A1C") +
  geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2,
                 position=position_dodge(0.05), color="#E41A1C") +
  theme_bw() +
  labs(x = "Dimension", y = "Mean Prediction Error (MIC units)") 

D

ggsave("S_pneumo_comb_pred_error_map_cross_validation.jpg")


```


